"""
–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.

–£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –Ω–∞ –¥–∏—Å–∫–µ, –Ω–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.
–≠—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–æ–∏–∑–æ–π—Ç–∏ –ø–æ—Å–ª–µ –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤ –∏–º–ø–æ—Ä—Ç–∞ —Å —Ñ–ª–∞–≥–æ–º --refresh-images.
"""
import argparse
from pathlib import Path

from sqlalchemy import select

from app.infrastructure.config.config import APP_CONFIG
from app.infrastructure.database.adapters.sync_connection import sync_session_maker
from app.infrastructure.database.models.product import ProductImage


def get_used_image_paths(session) -> set[str]:
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –ø—É—Ç–∏ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–º –≤ –ë–î."""
    images = session.scalars(select(ProductImage)).all()
    return {img.image_path for img in images}


def find_orphaned_images(images_dir: Path, used_paths: set[str]) -> list[Path]:
    """–ù–∞–π—Ç–∏ —Ñ–∞–π–ª—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –ë–î."""
    orphaned = []
    products_dir = images_dir / "products"
    
    if not products_dir.exists():
        return orphaned
    
    for image_file in products_dir.glob("*.webp"):
        relative_path = f"products/{image_file.name}"
        if relative_path not in used_paths:
            orphaned.append(image_file)
    
    return orphaned


def cleanup_orphaned_images(dry_run: bool = True) -> None:
    """–£–¥–∞–ª–∏—Ç—å –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ñ–∞–π–ª—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."""
    images_dir = Path(APP_CONFIG.IMAGES_DIR)
    
    with sync_session_maker() as session:
        used_paths = get_used_image_paths(session)
    
    orphaned = find_orphaned_images(images_dir, used_paths)
    
    if not orphaned:
        print("‚úÖ –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return
    
    total_size = sum(f.stat().st_size for f in orphaned)
    print(f"üóëÔ∏è  –ù–∞–π–¥–µ–Ω–æ {len(orphaned)} –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤ ({total_size / 1024 / 1024:.2f} MB)")
    
    if dry_run:
        print("\nüîç –†–µ–∂–∏–º dry-run, —Ñ–∞–π–ª—ã –Ω–µ –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã:")
        for idx, file_path in enumerate(orphaned[:10], 1):
            print(f"  [{idx}] {file_path.name} ({file_path.stat().st_size / 1024:.1f} KB)")
        if len(orphaned) > 10:
            print(f"  ... –∏ –µ—â—ë {len(orphaned) - 10} —Ñ–∞–π–ª–æ–≤")
        print("\nüí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å —Ñ–ª–∞–≥–æ–º --execute –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è")
    else:
        deleted = 0
        errors = 0
        for file_path in orphaned:
            try:
                file_path.unlink()
                deleted += 1
            except Exception as exc:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {file_path.name}: {exc}")
                errors += 1
        
        print(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ: {deleted} —Ñ–∞–π–ª–æ–≤")
        if errors:
            print(f"‚ùå –û—à–∏–±–æ–∫: {errors}")


def main() -> None:
    parser = argparse.ArgumentParser(
        description="–û—á–∏—Å—Ç–∫–∞ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"
    )
    parser.add_argument(
        "--execute",
        action="store_true",
        help="–í—ã–ø–æ–ª–Ω–∏—Ç—å —É–¥–∞–ª–µ–Ω–∏–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫)",
    )
    args = parser.parse_args()
    
    cleanup_orphaned_images(dry_run=not args.execute)


if __name__ == "__main__":
    main()

